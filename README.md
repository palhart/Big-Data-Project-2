# PySpark Data Processing and Visualization Dashboard

![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

## ðŸ“Œ Project Overview

This repository provides a robust data processing and visualization solution using PySpark, Docker, and a web dashboard. The application offers a complete pipeline for data ingestion, transformation, and interactive visualization.

## ðŸš€ Features

- **Dockerized Microservices Architecture**
- **PySpark-powered Data Processing**
- **Scalable Data Ingestion**
- **Interactive Web Dashboard**
- **Containerized Deployment**


## ðŸ“¦ Project Structure

```
.
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ analytics
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ analytics.py
â”‚Â Â  â””â”€â”€ load_data.py
â”œâ”€â”€ application_photo_and_ML_html
â”‚   â”œâ”€â”€ App_image_1.png
â”‚   â”œâ”€â”€ App_image_10.png
â”‚   â”œâ”€â”€ App_image_2.png
â”‚   â”œâ”€â”€ App_image_3.png
â”‚   â”œâ”€â”€ App_image_4.png
â”‚   â”œâ”€â”€ App_image_5.png
â”‚   â”œâ”€â”€ App_image_6.png
â”‚   â”œâ”€â”€ App_image_7.png
â”‚   â”œâ”€â”€ App_image_8.png
â”‚   â”œâ”€â”€ App_image_9.png
â”‚   â””â”€â”€ ml_analysis.html
â”œâ”€â”€ common
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â””â”€â”€ app.py
â”œâ”€â”€ data_ingestion
â”‚Â Â  â””â”€â”€ data_ingestion.py
â”œâ”€â”€ data_processing
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ data_cleaning.py
â”‚Â Â  â”œâ”€â”€ data_pipeline.py
â”‚Â Â  â””â”€â”€ data_processing.py
â”œâ”€â”€ docker
â”‚Â Â  â”œâ”€â”€ dashboard
â”‚Â Â  â”‚Â Â  â””â”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ data_processing
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”‚Â Â  â””â”€â”€ requirements.txt
â”‚Â Â  â””â”€â”€ ingestion
â”‚Â Â      â”œâ”€â”€ Dockerfile
â”‚Â Â      â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ hadoop-config
â”‚Â Â  â””â”€â”€ config.env
â”œâ”€â”€ ml_module
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ churn.py
â”‚   â”œâ”€â”€ customer_segmentation.py
â”‚   â””â”€â”€ ml_analysis.ipynb
â””â”€â”€ sql-analytics
    â”œâ”€â”€ README.md
    â”œâ”€â”€ load_data.py
    â”œâ”€â”€ sql_analytics.py
    â””â”€â”€ sql_queries.py

```

## ðŸ”§ Installation and Setup

### 1. Build Services

```bash
# Using Make (recommended)
make build

# Alternative Docker Compose command
docker-compose build
```

### 3. Run the Application

```bash
# Using Make
make run

# Alternative Docker Compose command
docker-compose up -d
```
### 4. Acces HDFS database 

Open yout web browser and navigate to: 
- HDFS URL: `http://localhost:9870/`


### 5. Access the Dashboard

Open your web browser and navigate to:
- Dashboard URL: `http://localhost:8050`

## ðŸ“‹ Makefile Commands

| Command | Description |
|---------|-------------|
| `make build` | Build all Docker images |
| `make run` | Start all services |
| `make stop` | Stop all running services |
| `make rm` | Remove containers and images |

## ðŸ”¬ Services

### 1. Ingestion Service
- Processes raw data
- Writes data to distributed storage
- Uses PySpark for efficient data handling

### 2. Data Processing Service
- Performs advanced data transformations
- Applies business logic and data cleaning
- Prepares data for visualization
- More information : [Data Processing](data_processing/README.md)

### 3. Dashboard Service
- In-depth analysis of the dataset using PySpark SQL
- Web-based interactive dashboard
- Real-time data visualization
- Responsive design
- More information: [Dashboard](analytics/README.md) and [Sql Analytics](sql_analytics/README.md)

### 4. Machine Learning
- Use Spark ML to make some ML on the dataset
- Add churn forecasting and customer segmentation
- Not included inside the Docker container
- More information: [Machine Learning](ml_module/README.md)

### 5. Application photo and ML html
- Screenshots of the application with all analysis
- HTML of the notebook from the ml_module folder

## ðŸ“š Resources

- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)
- [Docker Documentation](https://docs.docker.com/)
- [Plotly Dash Documentation](https://dash.plotly.com/)

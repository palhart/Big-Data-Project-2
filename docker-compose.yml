version: "3.9"

networks:
  hadoop-net:
    driver: bridge

services:
  # Distributed storage
  hdfs-namenode:
    container_name: "hdfs-namenode"
    image: "apache/hadoop:3"
    hostname: "hdfs-namenode"
    command: ["hdfs", "namenode"]
    ports:
      - "8020:8020"
      - "9870:9870"
    env_file:
      - ./hadoop-config/config.env
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    networks:
      - hadoop-net

  hdfs-datanode:
    depends_on:
      hdfs-namenode:
        condition: service_started
    container_name: "hdfs-datanode"
    image: "apache/hadoop:3"
    hostname: "hdfs-datanode"
    command: ["hdfs", "datanode"]
    ports:
      - "9864:9864"
    env_file:
      - ./hadoop-config/config.env
    networks:
      - hadoop-net
  
  data-ingestion:
    image: pyspark-hdfs-writer
    depends_on:
      - hdfs-namenode
      - hdfs-datanode
    networks:
      - hadoop-net
    volumes:
      - /data/BigData/ecommerce_data_with_trends.csv:/data/BigData/ecommerce_data_with_trends.csv

